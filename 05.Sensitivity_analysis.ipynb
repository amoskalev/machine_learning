{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artem Moskalev. Home Assignment -- 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (19 pt.): Model selection and sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (2 pt.): Information criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that regression model is\n",
    "$$y = \\sum_{i=1}^k \\beta_i x_i + \\varepsilon,$$\n",
    "and $\\varepsilon$ is dictributed as normally: $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$, $\\sigma^2$ is known.\n",
    "\n",
    "Prove that the model with highest Akaike information criterion is the model with smallest Mallow's $C_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEGIN Solution**\n",
    "\n",
    "From lectures:\n",
    "\n",
    "$AIC = k\\ln(\\frac 1 {\\sqrt{2\\pi}\\sigma}) - \\frac 1 {2\\sigma^2} \\sum_{i=1}^k(y_i - f(\\beta_J;x_{i,J}))^2 - |J|$\n",
    "\n",
    "$C_p = \\frac 1 k \\sum_{i=1}^k(y_i - f(\\beta_J;x_{i,J}))^2 + 2 \\frac {\\sigma^2} k |J|$\n",
    "\n",
    "As we are comparing an estimation of these criterions for the same model, we can get rid of all constants: \n",
    "\n",
    "$AIC^{'} = - \\sum_{i=1}^k(y_i - f(\\beta_J;x_{i,J}))^2 - |J|$\n",
    "\n",
    "$C_p^{'} = \\sum_{i=1}^k(y_i - f(\\beta_J;x_{i,J}))^2 + |J|$ \n",
    "\n",
    "From here we can vividly see that $\\max_{|J|} AIC = \\min_{|J|} C_p$\n",
    "\n",
    "**END Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (17 pt.): Sensitivity analysis and optimization for rotating disk problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tsk, you are proposed to solve a problem of optimization of a rotating disc. You will use approximation techniques, sensitivity analysis and optimization. For sensitivity analysis you are recommended to use SALib library (https://github.com/SALib/SALib), and scipy for optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Parameters `r1,t1,r2,r3,t3,r4` are input variables that define a geometrical shape of a disk. Parameters `mass,smax,u2` are mass of a disk, maximal radial stress, and contact stress, respectively. **Those are the\n",
    "target variables to predict (yes there are three regression targets).**\n",
    "2. The `problem` Pythonic dict is used for SALib methods and defines bounds for parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command in the next empty code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "!pip install salib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from SALib.analyze import sobol as sobol_analyzer\n",
    "from SALib.analyze import morris as morris_analyzer\n",
    "\n",
    "from SALib.sample import saltelli as saltelli_sampler\n",
    "from SALib.sample import morris as morris_sampler\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is defined as a simple Pythonic dict, where you should number of input variables,\n",
    "bounds for each input variable and their names. This will be helpful for sensitivity analysis.\n",
    "Note, that bounds defined here are true for **standardized data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/doe_100.csv')\n",
    "\n",
    "problem = {\n",
    "    'num_vars': 6,\n",
    "    'names': data.columns.values[:6],\n",
    "    'bounds': np.array([[-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321]]),\n",
    "    'groups': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sscaler = StandardScaler()\n",
    "\n",
    "X = pd.DataFrame(sscaler.fit_transform(data[problem['names']].copy()), columns=problem['names'])\n",
    "y = data[list(set(data.columns.values) - set(X.columns.values))]\n",
    "t1, t2, t3 = y.iloc[:,0], y.iloc[:,1], y.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 (7 pt.): Surrogate modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual dependency is not given, only a data set of inputs and outputs.\n",
    "Surrogate modelling is an approach that allows to construct approximations of the real dependecy, and use them for optimization and modelling.\n",
    "To perform sensitivity analysis and optimization we are going to use a regression model.\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "* Load the data set from `data/doe_100.csv`.\n",
    "* Build several regression models using different techniques: Gaussian Process Regression, Kernel Ridge regression, SVR.\n",
    "* Perform k-fold cross-validation for each model and choose the best.\n",
    "\n",
    "The most accurate models will be used in **all subsequent excersices**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**NOTE**</span> sklearn has a convenient GP implementation.\n",
    "\n",
    "```python\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import My, Favourite, Kernels, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1011)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model per target:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
       "      kernel_params=None),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'alpha': [0.001, 0.05, 0.1, 0.5, 0.8, 1.0, 1.5], 'kernel': ['linear', 'poly', 'rbf'], 'degree': array([1, 2, 3, 4, 5, 6, 7]), 'gamma': array([1, 2, 3, 4, 5, 6, 7]), 'coef0': array([ 0.1    ,  0.41667,  0.73333,  1.05   ,  1.36667,  1.68333,  2.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kridge = KernelRidge()\n",
    "kridge_params = {'alpha':[1e-3,.05,.1,.5,.8,1.,1.5],\n",
    "                                  'kernel':['linear','poly','rbf'],\n",
    "                                  'degree':np.arange(1,8),\n",
    "                                  'gamma':np.arange(1,8),\n",
    "                                  'coef0':np.linspace(0.1,2,7)}\n",
    "    \n",
    "kridge_gs = GridSearchCV(kridge, kridge_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "kridge_gs.fit(X, t1)\n",
    "#print('KernelRidge 3-CV r2 score for t1:', kridge_gs.best_score_, ' with params:', kridge_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/art_mos/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ 2.93263869]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
       "             n_restarts_optimizer=0, normalize_y=False,\n",
       "             optimizer='fmin_l_bfgs_b', random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'kernel': [RBF(length_scale=2), RBF(length_scale=4), RBF(length_scale=5), RBF(length_scale=7), Matern(length_scale=2, nu=1.5), Matern(length_scale=4, nu=1.5), Matern(length_scale=7, nu=0.8), Matern(length_scale=7, nu=1), Matern(length_scale=7, nu=0.6), Matern(length_scale=7, nu=0.6)], 'alpha': [1e-10, 1e-06, 0.001, 0.1, 1.0, 2.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr = GaussianProcessRegressor()\n",
    "gpt_params = {'kernel':[RBF(2), RBF(4), RBF(5), RBF(7),\n",
    "                                      Matern(2), Matern(4), Matern(7, nu=0.8), Matern(7, nu=1.),\n",
    "                                      Matern(7, nu=0.6), Matern(7, nu=0.6)],\n",
    "                            'alpha':[1e-10, 1e-6, 1e-3,1e-1,1.,2.]}\n",
    "\n",
    "\n",
    "gpr_gs = GridSearchCV(gpr, gpt_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "gpr_gs.fit(X,t1)\n",
    "#print('GaussianProcessRegressor 3-CV r2 score for t1:', gpr_gs.best_score_, ' with params:', gpr_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-30f55541af6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msvr_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvr_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msvr_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KernelRidge 3-CV r2 score for t1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkridge_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' with params:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkridge_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GaussianProcessRegressor 3-CV r2 score for t1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' with params:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr_params = {'C':np.linspace(0.1, 2., 5),\n",
    "                            'epsilon':np.linspace(0.01,1,7),\n",
    "                            'kernel':['linear','poly','rbf'],\n",
    "                            'degree':np.arange(2,8),\n",
    "                            'gamma':list(np.arange(2,8))+['auto'],\n",
    "                            'coef0':np.linspace(0.,2,7)}\n",
    "\n",
    "\n",
    "svr_gs = GridSearchCV(svr, svr_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "svr_gs.fit(X,t1)\n",
    "print('KernelRidge 3-CV r2 score for t1:', kridge_gs.best_score_, ' with params:', kridge_gs.best_params_)\n",
    "print('GaussianProcessRegressor 3-CV r2 score for t1:', gpr_gs.best_score_, ' with params:', gpr_gs.best_params_)\n",
    "print('SVR 3-CV r2 score for t1:', svr_gs.best_score_, ' with params:', svr_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kridge_gs = GridSearchCV(kridge, kridge_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "kridge_gs.fit(X, t2)\n",
    "print('KernelRidge 3-CV r2 score for t2:', kridge_gs.best_score_, ' with params:', kridge_gs.best_params_)\n",
    "\n",
    "gpr_gs = GridSearchCV(gpr, gpt_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "gpr_gs.fit(X,t2)\n",
    "print('GaussianProcessRegressor 3-CV r2 score for t2:', gpr_gs.best_score_, ' with params:', gpr_gs.best_params_)\n",
    "\n",
    "svr_gs = GridSearchCV(svr, svr_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "svr_gs.fit(X,t2)\n",
    "print('SVR 3-CV r2 score for t2:', svr_gs.best_score_, ' with params:', svr_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kridge_gs = GridSearchCV(kridge, kridge_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "kridge_gs.fit(X, t3)\n",
    "print('KernelRidge 3-CV r2 score for t3:', kridge_gs.best_score_, ' with params:', kridge_gs.best_params_)\n",
    "\n",
    "gpr_gs = GridSearchCV(gpr, gpt_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "gpr_gs.fit(X,t3)\n",
    "print('GaussianProcessRegressor 3-CV r2 score for t3:', gpr_gs.best_score_, ' with params:', gpr_gs.best_params_)\n",
    "\n",
    "svr_gs = GridSearchCV(svr, svr_params, scoring='r2',n_jobs=-1, verbose=0)\n",
    "svr_gs.fit(X,t3)\n",
    "print('SVR 3-CV r2 score for t3:', svr_gs.best_score_, ' with params:', svr_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Thus, the model per target will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0.5, coef0=2.0, degree=2, gamma=7, kernel='poly',\n",
       "      kernel_params=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1= SVR(**{'C': 2.0, 'coef0': 2.0, 'degree': 3, 'epsilon': 0.01, 'gamma': 'auto', 'kernel': 'poly'}) #first target\n",
    "model1.fit(X,t1)\n",
    "\n",
    "model2= SVR(**{'C': 2.0, 'coef0': 2.0, 'degree': 3, 'epsilon': 0.01, 'gamma': 'auto', 'kernel': 'poly'}) #second target\n",
    "model2.fit(X,t2)\n",
    "\n",
    "model3= KernelRidge(**{'alpha': 0.5, 'coef0': 2.0, 'degree': 2, 'gamma': 7, 'kernel': 'poly'}) #third target\n",
    "model3.fit(X,t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 (6 pt.): Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SALib is a python library for sensitivity analysis.\n",
    "\n",
    "It implements some popular global sensitivity analysis methods: \n",
    "* Morris method - that may be thought of as crude estimation of average absolute value of partial derivative. \n",
    "* Sobol indicies - that show portion of variance in the output that is explained by input.\n",
    "\n",
    "Each method takes **x** and **y** samples as input. But the samples must be properly generated.\n",
    "There are special functions in SALib library to do exactly that.\n",
    "\n",
    "Using the **best model per target** your task is to\n",
    "\n",
    "* calculate Sobol indices:\n",
    "    * Generate **x** and **y** samples using Saltelli’s extension of the Sobol sequence\n",
    "    * Calculate Sobol indices using obtained samples\n",
    "* calculate screening indices\n",
    "    * Generate **x** and **y** samples for Morris method\n",
    "    * Apply Morris method to generated samples to obtain screening indices\n",
    "\n",
    "\n",
    "* Using your judgement and based on the analysis results choose variables have the most influence on the output.\n",
    "\n",
    "**NOTE** Make sure to use the *same sample* for all three targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_gen = saltelli_sampler.sample(problem,100)\n",
    "\n",
    "Y1,Y2,Y3 = np.zeros([X_gen.shape[0]]),np.zeros([X_gen.shape[0]]),np.zeros([X_gen.shape[0]])\n",
    "\n",
    "for i, samp in enumerate(X_gen):\n",
    "    Y1[i] = model1.predict(samp.reshape(1,-1))\n",
    "    Y2[i] = model2.predict(samp.reshape(1,-1))\n",
    "    Y3[i] = model3.predict(samp.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Si1 = sobol_analyzer.analyze(problem, Y1, conf_level=0.95)\n",
    "Si2 = sobol_analyzer.analyze(problem, Y2, conf_level=0.95)\n",
    "Si3 = sobol_analyzer.analyze(problem, Y3, conf_level=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Target 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02040063  0.95613619 -0.00410823  0.02849199  0.01538022  0.01790955]\n"
     ]
    }
   ],
   "source": [
    "print(Si1['S1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that x2 exhibits huge first-order sensitivity, other variables have low first-order effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02518007  0.96685884  0.00160019  0.01921074  0.02785201  0.00295729]\n"
     ]
    }
   ],
   "source": [
    "print(Si1['ST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the total-order indices don't substantially differ from the first-order indices, that means that there are weak or no higher-order interactions occurring. So, there should not be strong interactions between variables. Let's see second-order Sobol indices to check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        nan -0.02110259 -0.02577954 -0.02603588 -0.01649683 -0.02682967]\n",
      " [        nan         nan -0.01081665 -0.03226091 -0.01209764 -0.03641273]\n",
      " [        nan         nan         nan  0.01374413  0.01508208  0.01365356]\n",
      " [        nan         nan         nan         nan -0.01950479 -0.0240186 ]\n",
      " [        nan         nan         nan         nan         nan  0.0250705 ]\n",
      " [        nan         nan         nan         nan         nan         nan]]\n"
     ]
    }
   ],
   "source": [
    "print(Si1['S2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly as we thought - no second order strong interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Target 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35525996  0.37616483  0.00862226  0.01541164  0.11158853  0.00868669] <- S1 \n",
      "\n",
      "[ 0.3666493   0.50880888  0.00572913  0.00571769  0.17833519  0.01294143] <- ST \n",
      "\n",
      "[[        nan -0.03103713 -0.10831783 -0.11478058 -0.08949731 -0.09934107]\n",
      " [        nan         nan  0.0930696   0.07478713  0.15162494  0.08496891]\n",
      " [        nan         nan         nan -0.00438774 -0.0142448  -0.00151468]\n",
      " [        nan         nan         nan         nan -0.03031057 -0.02706972]\n",
      " [        nan         nan         nan         nan         nan  0.04851508]\n",
      " [        nan         nan         nan         nan         nan         nan]]\n"
     ]
    }
   ],
   "source": [
    "print(Si2['S1'], '<- S1','\\n')\n",
    "print(Si2['ST'], '<- ST','\\n')\n",
    "print(Si2['S2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model, evaluating target 2. Firstly, we see that first, second and fifths variables have significant first-order sensitivity. Second, we see that some of the total-order indices are substantially larger than corresponding first-order indices, it might signal that there are some higher-order interactions occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Target 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1361182   0.40440074  0.00923017  0.0106445   0.44356553  0.0133641 ] <- S1 \n",
      "\n",
      "[ 0.107001    0.4966764   0.00249246  0.00196676  0.48587901  0.00631838] <- ST \n",
      "\n",
      "[[        nan -0.05899648 -0.1202899  -0.1261944  -0.08673347 -0.12066573]\n",
      " [        nan         nan  0.0155911   0.02057242  0.09649109  0.0156277 ]\n",
      " [        nan         nan         nan -0.01778483 -0.01996824 -0.01814842]\n",
      " [        nan         nan         nan         nan -0.00279791 -0.01198684]\n",
      " [        nan         nan         nan         nan         nan  0.01602667]\n",
      " [        nan         nan         nan         nan         nan         nan]]\n"
     ]
    }
   ],
   "source": [
    "print(Si3['S1'], '<- S1','\\n')\n",
    "print(Si3['ST'], '<- ST','\\n')\n",
    "print(Si3['S2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model, evaluating target 3, again, first, second and fifth variables is considerably first-order sensitive, others are not - they probably do not give more or less significant contribution. As for the total-order indices, an increased second variable's index may signal that there are also some high-order interactions occurring with this variable. In interaction matrix, as well as with the model 2, we see that there are no significant connections between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ###### Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that first, second and fifth variable are ones with the highest interactions, so I suggest to keep them for reduced feature space. Let's check, what Morris will tell us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_gen = morris_sampler.sample(problem,100, num_levels=4, grid_jump=2)\n",
    "\n",
    "Y1,Y2,Y3 = np.zeros([X_gen.shape[0]]),np.zeros([X_gen.shape[0]]),np.zeros([X_gen.shape[0]])\n",
    "\n",
    "for i, samp in enumerate(X_gen):\n",
    "    Y1[i] = model1.predict(samp.reshape(1,-1))\n",
    "    Y2[i] = model2.predict(samp.reshape(1,-1))\n",
    "    Y3[i] = model3.predict(samp.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mi1 = morris_analyzer.analyze(problem, X_gen, Y1, num_levels=4,grid_jump=2)\n",
    "Mi2 = morris_analyzer.analyze(problem, X_gen, Y2, num_levels=4,grid_jump=2)\n",
    "Mi3 = morris_analyzer.analyze(problem, X_gen, Y3, num_levels=4,grid_jump=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvgAAAGvCAYAAAAuQaExAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwDAjPz/6Ngxt20BP5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 936x504 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(13,7))\n",
    "ax[0,0].barh(Mi1['names'],Mi1['mu'])\n",
    "ax[0,0].set_title('$\\mu_1$')\n",
    "ax[0,1].barh(Mi1['names'],Mi1['mu_star'])\n",
    "ax[0,1].set_title('$\\mu^*_1$')\n",
    "ax[1,0].barh(Mi1['names'],Mi1['sigma'])\n",
    "ax[1,0].set_title('$\\sigma_1$')\n",
    "ax[1,1].barh(Mi1['names'],Mi1['mu_star_conf'])\n",
    "ax[1,1].set_title('$\\mu^*_{conf 1}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6AAAAHwCAYAAAC41AJvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABhCAwoAAMAQ/z/3fpYK/l55AwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 936x504 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,4, figsize=(13,7))\n",
    "ax[0,0].barh(Mi2['names'],Mi2['mu'])\n",
    "ax[0,0].set_title('$\\mu_2$')\n",
    "ax[0,1].barh(Mi2['names'],Mi2['mu_star'])\n",
    "ax[0,1].set_title('$\\mu^*_2$')\n",
    "ax[1,0].barh(Mi2['names'],Mi2['sigma'])\n",
    "ax[1,0].set_title('$\\sigma_1$')\n",
    "ax[1,1].barh(Mi2['names'],Mi2['mu_star_conf'])\n",
    "ax[1,1].set_title('$\\mu^*_{conf 2}$')\n",
    "\n",
    "ax[0,2].barh(Mi3['names'],Mi3['mu'])\n",
    "ax[0,2].set_title('$\\mu_3$')\n",
    "ax[0,3].barh(Mi3['names'],Mi3['mu_star'])\n",
    "ax[0,3].set_title('$\\mu^*_3$')\n",
    "ax[1,2].barh(Mi3['names'],Mi3['sigma'])\n",
    "ax[1,2].set_title('$\\sigma_3$')\n",
    "ax[1,3].barh(Mi3['names'],Mi3['mu_star_conf'])\n",
    "ax[1,3].set_title('$\\mu^*_{conf 3}$');\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ###### Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, basically, we see the same. High $\\mu^*$ depicts factor with high overall influence, we see that it's again first, second and fifth variable, while their high $\\sigma$ detects either their interactions with other variables or non-linear effect on output. Anyway, both $\\mu^*$ and $\\sigma$ say that first, second and fifth features are the most influential, what coincides with conclusions we made in Sobol SA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3 (4 pt.): Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to optimize the **mass** of the rotating disk. It will be done with scipy optimizer via approximation, provided by the surrogate model. We assume that surrogate model is of reasonable quality. The optimization problem for full parameter space is prepared for you.\n",
    "\n",
    "The following optimization problem should be solved:\n",
    "\n",
    "$$\n",
    "{\\rm mass} \\rightarrow \\min_x \\\\\n",
    "\\mbox{subject to} \\quad S_{max}(x) \\le 600 \\\\\n",
    "\\qquad \\qquad U_2(x) \\le 0.3\n",
    "$$\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "* Perform optimization by running the code below\n",
    "* After performing sensitivity analysis you got the most influential features. Reestimate your models on the reduced feature space\n",
    "* Change the optimization problem statement so that it usess only the selected variables\n",
    "* Compare the optimal results for two formulations considered and make a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_models = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 2281319.680499761\n",
      "     jac: array([  45513.46875, -111982.75   ,   38772.25   ,    7540.5    ,\n",
      "         -7740.09375,   -2517.28125])\n",
      " message: 'Inequality constraints incompatible'\n",
      "    nfev: 8\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 4\n",
      " success: False\n",
      "       x: array([ 109.,   32.,  123.,  154.,    6.,  198.])\n"
     ]
    }
   ],
   "source": [
    "result = minimize(lambda x: best_models[0].predict(x.reshape(1, -1)),\n",
    "                  [109.0, 32.0, 123.0, 154.0, 6.0, 198.0],\n",
    "                  bounds=problem['bounds'],\n",
    "                  constraints=[{'type': 'ineq',\n",
    "                                'fun' : lambda x: 600 - best_models[1].predict(x.reshape(1, -1))\n",
    "                               },\n",
    "                               {'type': 'ineq',\n",
    "                                'fun' : lambda x: 0.3 - best_models[2].predict(x.reshape(1, -1))\n",
    "                               }])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - After performing sensitivity analysis you got the most influential features. Reestimate your models on the reduced feature space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reduced = X[['r1','t1','t3']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 reestimation on reduced feature space:  0.730796443208\n",
      "Model 2 reestimation on reduced feature space:  0.954497828066\n",
      "Model 3 reestimation on reduced feature space:  0.988671048291\n"
     ]
    }
   ],
   "source": [
    "model1= SVR(**{'C': 2.0, 'coef0': 2.0, 'degree': 3, 'epsilon': 0.01, 'gamma': 'auto', 'kernel': 'poly'}) #first target\n",
    "model1.fit(X_reduced,t1)\n",
    "\n",
    "model2= SVR(**{'C': 2.0, 'coef0': 2.0, 'degree': 3, 'epsilon': 0.01, 'gamma': 'auto', 'kernel': 'poly'}) #second target\n",
    "model2.fit(X_reduced,t2)\n",
    "\n",
    "model3= KernelRidge(**{'alpha': 0.5, 'coef0': 2.0, 'degree': 2, 'gamma': 7, 'kernel': 'poly'}) #third target\n",
    "model3.fit(X_reduced,t3)\n",
    "\n",
    "print('Model 1 reestimation on reduced feature space: ',cross_val_score(model1, X_reduced, t1).mean())\n",
    "print('Model 2 reestimation on reduced feature space: ',cross_val_score(model2, X_reduced, t2).mean())\n",
    "print('Model 3 reestimation on reduced feature space: ',cross_val_score(model3, X_reduced, t3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Change the optimization problem statement so that it usess only the selected variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_models = [model1, model2, model3]\n",
    "\n",
    "problem_red = {\n",
    "    'num_vars': 3,\n",
    "    'names':['r1','t1','t3'],\n",
    "    'bounds': np.array([[-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321]]),\n",
    "    'groups': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: -5866553.26043456\n",
      "     jac: array([-43608.4375, -23559.4375, -99255.4375])\n",
      " message: 'Inequality constraints incompatible'\n",
      "    nfev: 5\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 4\n",
      " success: False\n",
      "       x: array([ 109.,   32.,  123.])\n"
     ]
    }
   ],
   "source": [
    "result = minimize(lambda x: best_models[0].predict(x.reshape(1, -1)),\n",
    "                  [109.0, 32.0, 123.0],\n",
    "                  bounds=problem_red['bounds'],\n",
    "                  constraints=[{'type': 'ineq',\n",
    "                                'fun' : lambda x: 600 - best_models[1].predict(x.reshape(1, -1))\n",
    "                               },\n",
    "                               {'type': 'ineq',\n",
    "                                'fun' : lambda x: 0.3 - best_models[2].predict(x.reshape(1, -1))\n",
    "                               }])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare the optimal results for two formulations considered and make a conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that, we that for variables of reduced feature space optimization in both cases gives approximately same results. These variables carry a lot of information. If we, for example, try to exclude the second variable but leave all others, our overall performance would not be so great. However, using first, second and fifth features, (in fact, we reduce our feature space by a half!) we achieve amazing performance, which is only slightly (0.5-1%) worse than the full feature space performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
